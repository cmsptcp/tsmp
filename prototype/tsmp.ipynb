{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install spark-nlp: recommended to use this command in bash\n",
    "# !conda install --yes -c johnsnowlabs spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.sql.functions import explode, col\n",
    "from functools import reduce\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sparknlp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure and start Spark Session: ##\n",
    "* master('local[*]') -> as many workers as logical cores on machine\n",
    "* arrow szhould be enabled to use pandas_udf\n",
    "* spark-nlp enabled (alternative: use spark = sparknlp.start())\n",
    "* spark.rpc.message.maxSize - 128 is default, increase when java errors observed with rpc size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 ms, sys: 42.8 ms, total: 66.1 ms\n",
      "Wall time: 8.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# def start_spark():\n",
    "#     builder = SparkSession.builder \\\n",
    "#     .appName(\"tsmp - social media based stock market value prediction\")\\\n",
    "#     .master('local[5]') \\\n",
    "#     .config(\"spark.driver.memory\",\"16G\")\\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "#     .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "#     .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.1.0\")\\      \n",
    "#     .config(\"spark.executor.memory\", \"2G\") \\\n",
    "#     .config('spark.sql.execution.arrow.enabled', 'true') \\\n",
    "#     .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "#     .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\\\n",
    "#     .config(\"spark.rpc.message.maxSize\", \"1000\")\n",
    "#     return builder.getOrCreate()\n",
    "\n",
    "# spark = start_spark()\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tweets data preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_path = '/home/jovyan/work/input_data/json/tweets_merged/'\n",
    "tweets_path = '/home/jovyan/my_files/json/tweets_merged/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial preprocessing of tweets json data\n",
    "def json_tweets_preprocessing(tweets_json_df):\n",
    "    \n",
    "    # explode data array to rows of twitter data\n",
    "    tweets_rows = tweets_json_df \\\n",
    "        .select(explode(\"data\").alias(\"tweets\"))\n",
    "        # .limit(4500)\n",
    "       \n",
    "    # remove tweets with language different than English\n",
    "    # select only columns used in further processing \n",
    "    # leave only distinct values (remove obvious duplicates)\n",
    "    tweets_data = tweets_rows \\\n",
    "        .filter(\n",
    "            col(\"tweets.lang\") == \"en\"\n",
    "        ) \\\n",
    "        .filter(\n",
    "            (col(\"tweets.public_metrics.like_count\") >= 10) | \\\n",
    "            (col(\"tweets.public_metrics.quote_count\") >= 10) | \\\n",
    "            (col(\"tweets.public_metrics.reply_count\") >= 10) | \\\n",
    "            (col(\"tweets.public_metrics.retweet_count\") >= 10)\n",
    "        ) \\\n",
    "        .select(\n",
    "            col(\"tweets.id\").alias(\"id\") \n",
    "          , col(\"tweets.text\").alias(\"text\")\n",
    "          , col(\"tweets.public_metrics.like_count\").alias(\"like_count\")\n",
    "          , col(\"tweets.public_metrics.quote_count\").alias(\"quote_count\")\n",
    "          , col(\"tweets.public_metrics.reply_count\").alias(\"reply_count\")\n",
    "          , col(\"tweets.public_metrics.retweet_count\").alias(\"retweet_count\")\n",
    "          , col(\"tweets.author_id\").alias(\"author_id\")\n",
    "          , col(\"tweets.created_at\").alias(\"created_at\")\n",
    "          , col(\"tweets.conversation_id\").alias(\"conversation_id\")\n",
    "          , col(\"tweets.in_reply_to_user_id\").alias(\"in_reply_to_user_id\")\n",
    "        ) \\\n",
    "        .distinct() \\\n",
    "        .withColumn(\"created_at_timestamp\",F.from_utc_timestamp(col(\"created_at\"), \"GMT\")) \\\n",
    "        .withColumn(\"created_at_date\", F.to_date(col(\"created_at\"))) \\\n",
    "        .orderBy(\"created_at_timestamp\", ascending=True)\n",
    "\n",
    "\n",
    "    \n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to analyze: 10\n",
      "CPU times: user 1.53 ms, sys: 809 µs, total: 2.33 ms\n",
      "Wall time: 1.31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets_json_file_paths = []\n",
    "for file in os.listdir(tweets_path):\n",
    "    if file.startswith(\"tweets\") and file.endswith(\".json\"): \n",
    "        tweets_json_file_paths.append(os.path.join(tweets_path, file))\n",
    "print(f'Files to analyze: {len(tweets_json_file_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_AMZN_merged_1611788377913.json for company AMZN\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_MSFT_merged_1611788415837.json for company MSFT\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_MCD_merged_1611788399786.json for company MCD\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_INTC_merged_1611788389654.json for company INTC\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_NFLX_merged_1611788430702.json for company NFLX\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_TSLA_merged_1611788475071.json for company TSLA\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_AMD_merged_1611788368385.json for company AMD\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_PFE_merged_1611788444379.json for company PFE\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_SBUX_merged_1611788459996.json for company SBUX\n",
      "file found: /home/jovyan/my_files/json/tweets_merged/tweets_QCOM_merged_1611788454991.json for company QCOM\n",
      "CPU times: user 1.06 ms, sys: 559 µs, total: 1.61 ms\n",
      "Wall time: 867 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for tweets_json_file_path in tweets_json_file_paths:\n",
    "    company_code_pattern = \"merged\\/tweets_(.*?)_merged\"\n",
    "    company_code = re.search(company_code_pattern, tweets_json_file_path).group(1)\n",
    "    print(f'file found: {tweets_json_file_path} for company {company_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tweets sentiment analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration for tweets sentiment analysis. \n",
    "For performance puproses we create pretrained pipeline once (~950 MB download, issues observed with model loaded from disk and checking that model is loaded takes time...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_sentimentdl_use_twitter download started this may take some time.\n",
      "Approx size to download 935.1 MB\n",
      "[OK!]\n",
      "CPU times: user 51.7 ms, sys: 30.6 ms, total: 82.3 ms\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiment_analysis_pipeline_dl_use_twitter = PretrainedPipeline(\"analyze_sentimentdl_use_twitter\", lang = \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# analyze sentiment using pretrained pipeline from Spark NLP project\n",
    "# sentiment_dl_sparknlp_use_twitter https://nlp.johnsnowlabs.com/2021/01/18/analyze_sentimentdl_use_twitter_en.html\n",
    "# pipeline based on Universal Sentence Encoder\n",
    "# pretrained with data from Twitter\n",
    "# is_sentiment_positive & is_sentiment_negative added for easier data manipulation\n",
    "def analyze_sentiment_pretrained_pipeline(text_list, sentiment_analysis_pipeline):\n",
    "    pipeline = sentiment_analysis_pipeline\n",
    "        \n",
    "    sentiment_result = pipeline.fullAnnotate(text_list,'sentiment_dl_sparknlp_use_twitter')\n",
    "    \n",
    "    resultdf = sentiment_result.select(F.explode(F.arrays_zip('document.result', 'sentiment.result')).alias(\"cols\")) \\\n",
    "        .select(F.expr(\"cols['0']\").alias(\"text\"),\n",
    "                F.expr(\"cols['1']\").alias(\"sentiment_use_twitter\")) \\\n",
    "        .withColumn(\"is_sentiment_positive\", when(col(\"sentiment_use_twitter\") == \"positive\",1).otherwise(0)) \\\n",
    "        .withColumn(\"is_sentiment_negative\", when(col(\"sentiment_use_twitter\") == \"negative\",1).otherwise(0))\n",
    "    return resultdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate twitter data json files.\n",
    "Create tweets_with_sentiment_dfs dictionary of DataFrames for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_AMZN_merged_1611788377913.json for company AMZN\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_MSFT_merged_1611788415837.json for company MSFT\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_MCD_merged_1611788399786.json for company MCD\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_INTC_merged_1611788389654.json for company INTC\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_NFLX_merged_1611788430702.json for company NFLX\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_TSLA_merged_1611788475071.json for company TSLA\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_AMD_merged_1611788368385.json for company AMD\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_PFE_merged_1611788444379.json for company PFE\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_SBUX_merged_1611788459996.json for company SBUX\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "reading /home/jovyan/my_files/json/tweets_merged/tweets_QCOM_merged_1611788454991.json for company QCOM\n",
      "analyzing sentiment...\n",
      "merging sentiment data with tweets data...\n",
      "CPU times: user 396 ms, sys: 227 ms, total: 622 ms\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tweets_with_sentiment_dfs = {}\n",
    "\n",
    "for tweets_json_file_path in tweets_json_file_paths:\n",
    "    company_code_pattern = \"merged\\/tweets_(.*?)_merged\"\n",
    "    company_code = re.search(company_code_pattern, tweets_json_file_path).group(1)\n",
    "    \n",
    "    # for testing purpose we will process only one company file: AMZN\n",
    "    #if company_code != 'AMZN':\n",
    "    #    continue\n",
    "    \n",
    "    print(f'reading {tweets_json_file_path} for company {company_code}')\n",
    "    tweets_json_df = spark.read.option(\"multiline\", True).json(tweets_json_file_path)\n",
    "    tweets_data = json_tweets_preprocessing(tweets_json_df)\n",
    "       \n",
    "    print(f'analyzing sentiment...')\n",
    "    sentiment_resultdf = analyze_sentiment_pretrained_pipeline\\\n",
    "        (tweets_data.select('text'),sentiment_analysis_pipeline_dl_use_twitter)\n",
    "     \n",
    "    print(f'merging sentiment data with tweets data...')\n",
    "    tweets_with_sentiment_dfs[company_code] = tweets_data.join(sentiment_resultdf, on=\"text\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, text: string, id: string, like_count: string, quote_count: string, reply_count: string, retweet_count: string, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, sentiment_use_twitter: string, is_sentiment_positive: string, is_sentiment_negative: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_sentiment_dfs['TSLA'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example stats of sentiment (very slow due to usage of group by, better to be used with window functions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment stats for AMZN\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive|  825|\n",
      "|              neutral|   32|\n",
      "|             negative|  365|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for MSFT\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive| 1001|\n",
      "|              neutral|   56|\n",
      "|             negative|  436|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for MCD\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive|  992|\n",
      "|              neutral|  122|\n",
      "|             negative| 1182|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for INTC\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive|  770|\n",
      "|              neutral|   37|\n",
      "|             negative|  250|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for NFLX\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive| 1413|\n",
      "|              neutral|   78|\n",
      "|             negative|  488|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for TSLA\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive| 1140|\n",
      "|              neutral|   58|\n",
      "|             negative|  318|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for AMD\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive|  828|\n",
      "|              neutral|   67|\n",
      "|             negative|  331|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for PFE\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive|  582|\n",
      "|              neutral|   63|\n",
      "|             negative| 1850|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for SBUX\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive| 1111|\n",
      "|              neutral|  114|\n",
      "|             negative|  768|\n",
      "+---------------------+-----+\n",
      "\n",
      "Sentiment stats for QCOM\n",
      "+---------------------+-----+\n",
      "|sentiment_use_twitter|count|\n",
      "+---------------------+-----+\n",
      "|             positive|  290|\n",
      "|              neutral|    8|\n",
      "|             negative|   59|\n",
      "+---------------------+-----+\n",
      "\n",
      "CPU times: user 23 ms, sys: 40.2 ms, total: 63.2 ms\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for company_code in tweets_with_sentiment_dfs.keys():\n",
    "    \n",
    "#     if company_code != 'TSLA':\n",
    "#         continue\n",
    "    \n",
    "    print(f'Sentiment stats for {company_code}')\n",
    "    tweets_with_sentiment_dfs[company_code].groupBy('sentiment_use_twitter').count().show()\n",
    "    # print(f'Data time window start: {tweets_with_sentiment_dfs[key].first()}')\n",
    "    # print(f'Data time window end: {tweets_with_sentiment_dfs[key].last().}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- like_count: long (nullable = true)\n",
      " |-- quote_count: long (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- conversation_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id: string (nullable = true)\n",
      " |-- created_at_timestamp: timestamp (nullable = true)\n",
      " |-- created_at_date: date (nullable = true)\n",
      " |-- sentiment_use_twitter: string (nullable = true)\n",
      " |-- is_sentiment_positive: integer (nullable = true)\n",
      " |-- is_sentiment_negative: integer (nullable = true)\n",
      "\n",
      "CPU times: user 3.25 ms, sys: 0 ns, total: 3.25 ms\n",
      "Wall time: 11.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets_with_sentiment_dfs['AMZN'].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tweets_with_sentiment_dfs['AMZN'].show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Write results to disk as parquet (serialize for further use), \n",
    "```.coalesce(1).cache()``` \n",
    "was faster when saving to database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for key in tweets_with_sentiment_dfs.keys():\n",
    "#     file_name = f'merged_json_run_files/tweets_with_sentiment_{key}_parquet'\n",
    "#     print(f'Saving {key} data to parquet file: {file_name}, total sentiment stats for this file:')\n",
    "#     tweets_with_sentiment_dfs[key] \\\n",
    "#         .cache() \\\n",
    "#         .write.mode('overwrite') \\\n",
    "#         .partitionBy('created_at_date') \\\n",
    "#         .parquet(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results to hive/database (for testing purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for key in tweets_with_sentiment_dfs.keys():\n",
    "#     print(f'saving {key} data to table')\n",
    "#     tweets_with_sentiment_dfs[key] \\\n",
    "#         .cache() \\\n",
    "#         .write.mode('overwrite') \\\n",
    "#         .partitionBy('created_at_date') \\\n",
    "#         .saveAsTable(f'tweets_with_sentiment_{key}_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stock data preprocessing ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings for stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfinance_data_path = '/home/jovyan/work/input_data/json/stock/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used by stock data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# avg_tweet_lifespan = 18\n",
    "# alternative_tweet_adjust = 1\n",
    "\n",
    "def yfinance_json_to_df(file_name, yfinance_data_path, yfinance_data_dfs):\n",
    "    \n",
    "    file_path = os.path.join(yfinance_data_path, file_name)\n",
    "    yfinance_json = spark.read.json(file_path)\n",
    "    \n",
    "    company_code_pattern = \"stock_yfinance_(.*?)_\"\n",
    "    company_code = re.search(company_code_pattern, file_name).group(1)\n",
    "    \n",
    "    ticker_interval_pattern = \"_ti(.*?)m_\"\n",
    "    ticker_interval =  re.search(ticker_interval_pattern, file_name).group(1)\n",
    "    \n",
    "    interval_expr = ''\n",
    "    if ticker_interval == \"15\" or \"30\" or \"60\":\n",
    "        interval_expr = f'INTERVAL {ticker_interval} MINUTES'\n",
    "    else:\n",
    "        raise Exception(\"Ticker not found or not supported\")\n",
    "    \n",
    "    # adj_start_interval_expr = f'INTERVAL {alternative_tweet_adjust} MINUTES'\n",
    "    \n",
    "    # explode data array to rows of yahoo finance data\n",
    "    yfinance_rows = yfinance_json.select(explode(\"data\").alias(\"records\"))\n",
    "    \n",
    "    # round values for close/open/high/low to $0.001\n",
    "    # add columns with more descriptive data about stock result (gain/loss/no_change)\n",
    "    yfinance_data_df = yfinance_rows \\\n",
    "        .select(\n",
    "            col(\"records.Datetime\").alias(\"records_datetime\")\n",
    "          , F.round(col(\"records.Close\"),3).alias(\"close\") \n",
    "          , F.round(col(\"records.Open\"),3).alias(\"open\")\n",
    "          , F.round(col(\"records.High\"),3).alias(\"high\")\n",
    "          , F.round(col(\"records.Low\"),3).alias(\"low\")\n",
    "          , col(\"records.Volume\").alias(\"volume\")\n",
    "          , col(\"records.Dividends\").alias(\"dividends\")\n",
    "          , col(\"records.Stock Splits\").alias(\"stock_splits\")\n",
    "        ) \\\n",
    "        .withColumn(\"records_date\", F.to_date(col(\"records_datetime\"))) \\\n",
    "        .withColumn(\"open_timestamp\", F.from_utc_timestamp(col(\"records_datetime\"), \"GMT\")) \\\n",
    "        .withColumn(\"close_timestamp\", col(\"open_timestamp\")+F.expr(interval_expr)) \\\n",
    "        .withColumn(\"result_percent\", F.round((col(\"close\")-col(\"open\"))/col(\"open\"),5)) \\\n",
    "        .withColumn(\"result_numeric\", when( col(\"close\") >= col(\"open\"), 1) \\\n",
    "            .otherwise(0)\n",
    "        ) \\\n",
    "        .withColumn(\"result\", when( col(\"close\") >= col(\"open\"), \"gain\") \\\n",
    "            .otherwise(\"loss\")\n",
    "        ) \\\n",
    "        .orderBy(\"open_timestamp\", ascending=True)\n",
    "\n",
    "        #.withColumn(\"result_numeric\", when( col(\"close\") > col(\"open\"), 1) \\\n",
    "        #    .when( col(\"close\") < col(\"open\"), -1) \\\n",
    "        #    .otherwise(0)\n",
    "    \n",
    "        #.withColumn(\"result\", when( col(\"close\") > col(\"open\"), \"gain\") \\\n",
    "        #    .when( col(\"close\") < col(\"open\"), \"loss\") \\\n",
    "        #    .otherwise(\"no_change\")\n",
    "        #.withColumn(\"adjusted_tweet_start_timestamp\", col(\"open_timestamp\")-F.expr(adj_start_interval_expr)) \\\n",
    "    \n",
    "    if company_code not in yfinance_data_dfs.keys():\n",
    "        yfinance_data_dfs[company_code] = {}\n",
    "        \n",
    "    print(f'ticker time: {ticker_interval}, company code: {company_code}')\n",
    "    \n",
    "    yfinance_data_dfs[company_code][ticker_interval] = yfinance_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker time: 15, company code: AMD\n",
      "ticker time: 30, company code: AMD\n",
      "ticker time: 60, company code: AMD\n",
      "ticker time: 15, company code: AMZN\n",
      "ticker time: 30, company code: AMZN\n",
      "ticker time: 60, company code: AMZN\n",
      "ticker time: 15, company code: INTC\n",
      "ticker time: 30, company code: INTC\n",
      "ticker time: 60, company code: INTC\n",
      "ticker time: 15, company code: MCD\n",
      "ticker time: 30, company code: MCD\n",
      "ticker time: 60, company code: MCD\n",
      "ticker time: 15, company code: MSFT\n",
      "ticker time: 30, company code: MSFT\n",
      "ticker time: 60, company code: MSFT\n",
      "ticker time: 15, company code: NFLX\n",
      "ticker time: 30, company code: NFLX\n",
      "ticker time: 60, company code: NFLX\n",
      "ticker time: 15, company code: PFE\n",
      "ticker time: 30, company code: PFE\n",
      "ticker time: 60, company code: PFE\n",
      "ticker time: 15, company code: QCOM\n",
      "ticker time: 30, company code: QCOM\n",
      "ticker time: 60, company code: QCOM\n",
      "ticker time: 15, company code: SBUX\n",
      "ticker time: 30, company code: SBUX\n",
      "ticker time: 60, company code: SBUX\n",
      "ticker time: 15, company code: TSLA\n",
      "ticker time: 30, company code: TSLA\n",
      "ticker time: 60, company code: TSLA\n",
      "CPU times: user 551 ms, sys: 378 ms, total: 929 ms\n",
      "Wall time: 7.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yfinance_data_dfs = {}\n",
    "\n",
    "for file_name in os.listdir(yfinance_data_path):\n",
    "    if file_name.startswith(\"stock_yfinance\") and file_name.endswith('.json'):\n",
    "        yfinance_json_to_df(file_name, yfinance_data_path, yfinance_data_dfs)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yfinance_data_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More about data from Yahoo Finance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_code: AMD, ticker_interval: 15\n",
      "company_code: AMD, ticker_interval: 30\n",
      "company_code: AMD, ticker_interval: 60\n",
      "company_code: AMZN, ticker_interval: 15\n",
      "company_code: AMZN, ticker_interval: 30\n",
      "company_code: AMZN, ticker_interval: 60\n",
      "company_code: INTC, ticker_interval: 15\n",
      "company_code: INTC, ticker_interval: 30\n",
      "company_code: INTC, ticker_interval: 60\n",
      "company_code: MCD, ticker_interval: 15\n",
      "company_code: MCD, ticker_interval: 30\n",
      "company_code: MCD, ticker_interval: 60\n",
      "company_code: MSFT, ticker_interval: 15\n",
      "company_code: MSFT, ticker_interval: 30\n",
      "company_code: MSFT, ticker_interval: 60\n",
      "company_code: NFLX, ticker_interval: 15\n",
      "company_code: NFLX, ticker_interval: 30\n",
      "company_code: NFLX, ticker_interval: 60\n",
      "company_code: PFE, ticker_interval: 15\n",
      "company_code: PFE, ticker_interval: 30\n",
      "company_code: PFE, ticker_interval: 60\n",
      "company_code: QCOM, ticker_interval: 15\n",
      "company_code: QCOM, ticker_interval: 30\n",
      "company_code: QCOM, ticker_interval: 60\n",
      "company_code: SBUX, ticker_interval: 15\n",
      "company_code: SBUX, ticker_interval: 30\n",
      "company_code: SBUX, ticker_interval: 60\n",
      "company_code: TSLA, ticker_interval: 15\n",
      "company_code: TSLA, ticker_interval: 30\n",
      "company_code: TSLA, ticker_interval: 60\n",
      "CPU times: user 8.13 ms, sys: 2 ms, total: 10.1 ms\n",
      "Wall time: 4.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for company_code in sorted(yfinance_data_dfs.keys()):\n",
    "    for ticker_interval in sorted(yfinance_data_dfs[company_code].keys()):\n",
    "        print(f'company_code: {company_code}, ticker_interval: {ticker_interval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- records_datetime: string (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- dividends: long (nullable = true)\n",
      " |-- stock_splits: long (nullable = true)\n",
      " |-- records_date: date (nullable = true)\n",
      " |-- open_timestamp: timestamp (nullable = true)\n",
      " |-- close_timestamp: timestamp (nullable = true)\n",
      " |-- result_percent: double (nullable = true)\n",
      " |-- result_numeric: integer (nullable = false)\n",
      " |-- result: string (nullable = false)\n",
      "\n",
      "CPU times: user 1.28 ms, sys: 683 µs, total: 1.96 ms\n",
      "Wall time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "yfinance_data_dfs[\"AMZN\"][\"60\"].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "yfinance_data_dfs[\"AMZN\"][\"15\"].show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge tweets data with stock data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock data are in this case significantly smaller than tweets data (for single company and single week it is tens of kB vs hundreds of MB, about 1000 times smaller). That is the reason why *broadcast hash join* was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company code: AMZN, ticker interval: 15\n",
      "company code: AMZN, ticker interval: 30\n",
      "company code: AMZN, ticker interval: 60\n",
      "company code: MSFT, ticker interval: 15\n",
      "company code: MSFT, ticker interval: 30\n",
      "company code: MSFT, ticker interval: 60\n",
      "company code: MCD, ticker interval: 15\n",
      "company code: MCD, ticker interval: 30\n",
      "company code: MCD, ticker interval: 60\n",
      "company code: INTC, ticker interval: 15\n",
      "company code: INTC, ticker interval: 30\n",
      "company code: INTC, ticker interval: 60\n",
      "company code: NFLX, ticker interval: 15\n",
      "company code: NFLX, ticker interval: 30\n",
      "company code: NFLX, ticker interval: 60\n",
      "company code: TSLA, ticker interval: 15\n",
      "company code: TSLA, ticker interval: 30\n",
      "company code: TSLA, ticker interval: 60\n",
      "company code: AMD, ticker interval: 15\n",
      "company code: AMD, ticker interval: 30\n",
      "company code: AMD, ticker interval: 60\n",
      "company code: PFE, ticker interval: 15\n",
      "company code: PFE, ticker interval: 30\n",
      "company code: PFE, ticker interval: 60\n",
      "company code: SBUX, ticker interval: 15\n",
      "company code: SBUX, ticker interval: 30\n",
      "company code: SBUX, ticker interval: 60\n",
      "company code: QCOM, ticker interval: 15\n",
      "company code: QCOM, ticker interval: 30\n",
      "company code: QCOM, ticker interval: 60\n",
      "CPU times: user 22.9 ms, sys: 92.8 ms, total: 116 ms\n",
      "Wall time: 356 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql.functions import broadcast\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "\n",
    "tweets_with_sentiment_and_stock_results_df = {}\n",
    "\n",
    "for company_code in tweets_with_sentiment_dfs:\n",
    "    \n",
    "    # when we do not have stock data for this company we check another one\n",
    "    if company_code not in yfinance_data_dfs:\n",
    "        continue\n",
    "    \n",
    "    if company_code not in tweets_with_sentiment_and_stock_results_df:\n",
    "        tweets_with_sentiment_and_stock_results_df[company_code] = {}\n",
    "    \n",
    "    for ticker_interval in yfinance_data_dfs[company_code]:\n",
    "        \n",
    "        # if company_code != 'AMZN':\n",
    "        #    continue\n",
    "        \n",
    "        print(f'company code: {company_code}, ticker interval: {ticker_interval}')\n",
    "        \n",
    "        stock_data_df = yfinance_data_dfs[company_code][ticker_interval]\n",
    "        tweets_sentiment_df = tweets_with_sentiment_dfs[company_code]\n",
    "        \n",
    "        result_df = tweets_sentiment_df \\\n",
    "            .join(broadcast(yfinance_data_dfs[company_code][ticker_interval]), \\\n",
    "                  (stock_data_df.open_timestamp <= tweets_sentiment_df.created_at_timestamp) \\\n",
    "                  & (tweets_sentiment_df.created_at_timestamp < stock_data_df.close_timestamp), \\\n",
    "                  how='inner')\n",
    "#         result_df = tweets_sentiment_df \\\n",
    "#             .join(broadcast(yfinance_data_dfs[company_code][ticker_interval]), \\\n",
    "#                   (stock_data_df.adjusted_tweet_start_timestamp <= tweets_sentiment_df.created_at_timestamp) \\\n",
    "#                   & (tweets_sentiment_df.created_at_timestamp < stock_data_df.close_timestamp), \\\n",
    "#                   how='inner')\n",
    "        \n",
    "        tweets_with_sentiment_and_stock_results_df[company_code][ticker_interval] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMZN': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'MSFT': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'MCD': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'INTC': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'NFLX': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'TSLA': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'AMD': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'PFE': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'SBUX': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int],\n",
       " 'QCOM': DataFrame[text: string, id: string, like_count: bigint, quote_count: bigint, reply_count: bigint, retweet_count: bigint, author_id: string, created_at: string, conversation_id: string, in_reply_to_user_id: string, created_at_timestamp: timestamp, created_at_date: date, sentiment_use_twitter: string, is_sentiment_positive: int, is_sentiment_negative: int]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_sentiment_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_with_sentiment_and_stock_results_df has company_code:AMZN ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:AMZN ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:AMZN ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:MSFT ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:MSFT ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:MSFT ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:MCD ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:MCD ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:MCD ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:INTC ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:INTC ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:INTC ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:NFLX ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:NFLX ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:NFLX ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:TSLA ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:TSLA ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:TSLA ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:AMD ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:AMD ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:AMD ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:PFE ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:PFE ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:PFE ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:SBUX ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:SBUX ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:SBUX ticker_interval:60\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:QCOM ticker_interval:15\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:QCOM ticker_interval:30\n",
      "tweets_with_sentiment_and_stock_results_df has company_code:QCOM ticker_interval:60\n"
     ]
    }
   ],
   "source": [
    "for company_code in tweets_with_sentiment_and_stock_results_df:\n",
    "    for ticker_interval in tweets_with_sentiment_and_stock_results_df[company_code]:\n",
    "        print(f\"tweets_with_sentiment_and_stock_results_df has company_code:{company_code} ticker_interval:{ticker_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- like_count: long (nullable = true)\n",
      " |-- quote_count: long (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- conversation_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id: string (nullable = true)\n",
      " |-- created_at_timestamp: timestamp (nullable = true)\n",
      " |-- created_at_date: date (nullable = true)\n",
      " |-- sentiment_use_twitter: string (nullable = true)\n",
      " |-- is_sentiment_positive: integer (nullable = true)\n",
      " |-- is_sentiment_negative: integer (nullable = true)\n",
      " |-- records_datetime: string (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- dividends: long (nullable = true)\n",
      " |-- stock_splits: long (nullable = true)\n",
      " |-- records_date: date (nullable = true)\n",
      " |-- open_timestamp: timestamp (nullable = true)\n",
      " |-- close_timestamp: timestamp (nullable = true)\n",
      " |-- result_percent: double (nullable = true)\n",
      " |-- result_numeric: integer (nullable = false)\n",
      " |-- result: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_with_sentiment_and_stock_results_df[\"TSLA\"][\"15\"].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------+-----------+-----------+-------------+-------------------+--------------------+-------------------+-------------------+--------------------+---------------+---------------------+---------------------+---------------------+--------------------+-------+-------+------+-------+-------+---------+------------+------------+-------------------+-------------------+--------------+--------------+------+\n",
      "|                text|                 id|like_count|quote_count|reply_count|retweet_count|          author_id|          created_at|    conversation_id|in_reply_to_user_id|created_at_timestamp|created_at_date|sentiment_use_twitter|is_sentiment_positive|is_sentiment_negative|    records_datetime|  close|   open|  high|    low| volume|dividends|stock_splits|records_date|     open_timestamp|    close_timestamp|result_percent|result_numeric|result|\n",
      "+--------------------+-------------------+----------+-----------+-----------+-------------+-------------------+--------------------+-------------------+-------------------+--------------------+---------------+---------------------+---------------------+---------------------+--------------------+-------+-------+------+-------+-------+---------+------------+------------+-------------------+-------------------+--------------+--------------+------+\n",
      "|@elonmusk The lat...|1350145788643479552|        26|          0|          2|            0|           23402809|2021-01-15T18:20:...|1347356316763705344|           44196397| 2021-01-15 18:20:15|     2021-01-15|             negative|                    0|                    1|2021-01-15T18:15:...|  839.7|  835.2|840.85|834.991|1025843|        0|           0|  2021-01-15|2021-01-15 18:15:00|2021-01-15 18:30:00|       0.00539|             1|  gain|\n",
      "|@shipwreckedcrew ...|1348693384597172226|        66|          0|          4|            8|1205963854976450561|2021-01-11T18:08:...|1348692045951500288|           18034061| 2021-01-11 18:08:55|     2021-01-11|             positive|                    1|                    0|2021-01-11T18:00:...| 835.29|836.416|837.37|  831.3|1221381|        0|           0|  2021-01-11|2021-01-11 18:00:00|2021-01-11 18:15:00|      -0.00135|             0|  loss|\n",
      "|Another Tesla in ...|1348644761339572224|        56|          0|          2|            4|          206366112|2021-01-11T14:55:...|1348644761339572224|               null| 2021-01-11 14:55:42|     2021-01-11|             positive|                    1|                    0|2021-01-11T14:45:...| 838.99|828.859|839.25|  817.0|6088295|        0|           0|  2021-01-11|2021-01-11 14:45:00|2021-01-11 15:00:00|       0.01222|             1|  gain|\n",
      "|Hey $TSLAQ dummie...|1349083106775617539|        12|          1|          1|            0|1205703114415890433|2021-01-12T19:57:...|1349083106775617539|               null| 2021-01-12 19:57:32|     2021-01-12|             positive|                    1|                    0|2021-01-12T19:45:...|  854.0| 854.18|854.18| 850.19|1028743|        0|           0|  2021-01-12|2021-01-12 19:45:00|2021-01-12 20:00:00|       -2.1E-4|             0|  loss|\n",
      "|Tesla's entry in ...|1349060671997059073|       101|          1|          3|            1|           39240673|2021-01-12T18:28:...|1349060671997059073|               null| 2021-01-12 18:28:23|     2021-01-12|             positive|                    1|                    0|2021-01-12T18:15:...|858.985| 859.29|859.55|856.408| 510782|        0|           0|  2021-01-12|2021-01-12 18:15:00|2021-01-12 18:30:00|       -3.5E-4|             0|  loss|\n",
      "|$TSLA are u surpr...|1348704435401355264|        56|          1|          9|            8|           55561590|2021-01-11T18:52:...|1348704435401355264|               null| 2021-01-11 18:52:49|     2021-01-11|             positive|                    1|                    0|2021-01-11T18:45:...|829.635| 827.47|831.43|  824.2|1579189|        0|           0|  2021-01-11|2021-01-11 18:45:00|2021-01-11 19:00:00|       0.00262|             1|  gain|\n",
      "|@klwtts Tesla kno...|1349809660459552768|        15|          0|          3|            0|           14162718|2021-01-14T20:04:...|1349768668192727041| 912969880852299776| 2021-01-14 20:04:35|     2021-01-14|             positive|                    1|                    0|2021-01-14T20:00:...| 847.65| 848.77|849.83| 845.61| 586357|        0|           0|  2021-01-14|2021-01-14 20:00:00|2021-01-14 20:15:00|      -0.00132|             0|  loss|\n",
      "|Anyways, when I b...|1350184691224207364|        13|          0|          3|            1|         3403673529|2021-01-15T20:54:...|1350184691224207364|               null| 2021-01-15 20:54:50|     2021-01-15|             positive|                    1|                    0|2021-01-15T20:45:...| 826.06| 824.24|827.78| 823.76|1818222|        0|           0|  2021-01-15|2021-01-15 20:45:00|2021-01-15 21:00:00|       0.00221|             1|  gain|\n",
      "|You can’t make th...|1349015344883638275|        10|          2|          6|            2|1008739874583834624|2021-01-12T15:28:...|1349015344883638275|               null| 2021-01-12 15:28:16|     2021-01-12|             negative|                    0|                    1|2021-01-12T15:15:...| 860.02| 856.59| 865.0| 853.01|3031510|        0|           0|  2021-01-12|2021-01-12 15:15:00|2021-01-12 15:30:00|         0.004|             1|  gain|\n",
      "|@elonmusk @tesla ...|1349761100741369856|        46|          6|          8|           22|           54829446|2021-01-14T16:51:...|1349761100741369856|           44196397| 2021-01-14 16:51:38|     2021-01-14|             positive|                    1|                    0|2021-01-14T16:45:...|853.224|857.125|857.59|  850.2| 868587|        0|           0|  2021-01-14|2021-01-14 16:45:00|2021-01-14 17:00:00|      -0.00455|             0|  loss|\n",
      "+--------------------+-------------------+----------+-----------+-----------+-------------+-------------------+--------------------+-------------------+-------------------+--------------------+---------------+---------------------+---------------------+---------------------+--------------------+-------+-------+------+-------+-------+---------+------------+------------+-------------------+-------------------+--------------+--------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 4.3 ms, sys: 0 ns, total: 4.3 ms\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for company_code in tweets_with_sentiment_and_stock_results_df.keys():\n",
    "    for ticker_interval in tweets_with_sentiment_and_stock_results_df[company_code].keys():\n",
    "        \n",
    "        if company_code != 'TSLA' or ticker_interval != \"15\":\n",
    "            continue\n",
    "            \n",
    "        tweets_with_sentiment_and_stock_results_df[company_code][ticker_interval].show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Window operations ## \n",
    "# %%time\n",
    "# from pyspark.sql.window import Window\n",
    "\n",
    "# windowSpec = Window.partitionBy(\"close_timestamp\").orderBy(\"created_at_timestamp\")\n",
    "\n",
    "# for key in tweets_with_sentiment_and_stock_results_df.keys():\n",
    "#     for subkey in tweets_with_sentiment_and_stock_results_df[key].keys():\n",
    "        \n",
    "#         if key != 'AMZN' or subkey != \"60\":\n",
    "#             continue\n",
    "        \n",
    "#         the_data = tweets_with_sentiment_and_stock_results_df[key][subkey]\n",
    "        \n",
    "#         the_data.withColumn(\"rank\", F.rank().over(windowSpec)) \\\n",
    "#             .withColumn(\"dense_rank\", F.dense_rank().over(windowSpec)) \\\n",
    "#             .withColumn(\"row_num\", F.row_number().over(windowSpec)) \\\n",
    "#             .withColumn(\"popularity_factor\", F.count(the_data['id']).over(windowSpec)) \\\n",
    "#             .withColumn(\"cum_likes\", F.sum(the_data['like_count']).over(windowSpec)) \\\n",
    "#             .withColumn(\"cum_quotes\", F.sum(the_data['quote_count']).over(windowSpec)) \\\n",
    "#             .withColumn(\"cum_replies\", F.sum(the_data['reply_count']).over(windowSpec)) \\\n",
    "#             .withColumn(\"cum_retweets\", F.sum(the_data['retweet_count']).over(windowSpec)) \\\n",
    "#             .withColumn(\"authors_count\", F.count(the_data['author_id']).over(windowSpec)) \\\n",
    "#             .withColumn(\"conversations_count\", F.count(the_data['conversation_id']).over(windowSpec)) \\\n",
    "#             .withColumn(\"cum_retweet_count\", F.sum(the_data['retweet_count']).over(windowSpec)) \\\n",
    "#             .withColumn(\"positive_sentiment_factor\", F.avg(the_data['is_sentiment_positive']).over(windowSpec)) \\\n",
    "#             .show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GroupBy data in time intervals  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group data, count aggregated tweet stats for each time interval, merge with stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+----------------+------------------+----------------+------------------+------------------+------------------+----------------+----------------------+------------------+--------------------------+--------------------------+--------------------------+--------------------------+--------------------+-------+-------+-------+-------+-------+---------+------------+------------+-------------------+--------------+--------------+------+\n",
      "|    close_timestamp|count(id)|sum(like_count)|   avg(like_count)|sum(quote_count)|  avg(quote_count)|sum(reply_count)|  avg(reply_count)|sum(retweet_count)|avg(retweet_count)|count(author_id)|count(conversation_id)| avg(length(text))|sum(is_sentiment_positive)|sum(is_sentiment_negative)|avg(is_sentiment_positive)|avg(is_sentiment_negative)|    records_datetime|  close|   open|   high|    low| volume|dividends|stock_splits|records_date|     open_timestamp|result_percent|result_numeric|result|\n",
      "+-------------------+---------+---------------+------------------+----------------+------------------+----------------+------------------+------------------+------------------+----------------+----------------------+------------------+--------------------------+--------------------------+--------------------------+--------------------------+--------------------+-------+-------+-------+-------+-------+---------+------------+------------+-------------------+--------------+--------------+------+\n",
      "|2021-01-11 14:45:00|        3|            174|              58.0|               1|0.3333333333333333|              15|               5.0|                16| 5.333333333333333|               3|                     3|             122.0|                         1|                         2|        0.3333333333333333|        0.6666666666666666|2021-01-11T14:30:...| 833.13|  849.4| 853.23|  831.5|9416495|        0|           0|  2021-01-11|2021-01-11 14:30:00|      -0.01915|             0|  loss|\n",
      "|2021-01-11 15:00:00|       16|            792|              49.5|               9|            0.5625|              85|            5.3125|                41|            2.5625|              15|                    15|           156.875|                        14|                         2|                     0.875|                     0.125|2021-01-11T14:45:...| 838.99|828.859| 839.25|  817.0|6088295|        0|           0|  2021-01-11|2021-01-11 14:45:00|       0.01222|             1|  gain|\n",
      "|2021-01-11 15:15:00|        3|            430|143.33333333333334|               4|1.3333333333333333|              28| 9.333333333333334|                29| 9.666666666666666|               3|                     3|122.66666666666667|                         0|                         3|                       0.0|                       1.0|2021-01-11T15:00:...|  844.0| 838.93|  846.0| 834.54|3746883|        0|           0|  2021-01-11|2021-01-11 15:00:00|       0.00604|             1|  gain|\n",
      "|2021-01-11 15:30:00|        8|            302|             37.75|               1|             0.125|              26|              3.25|                18|              2.25|               7|                     8|           136.375|                         8|                         0|                       1.0|                       0.0|2021-01-11T15:15:...| 847.79| 843.76| 854.43| 843.03|3264282|        0|           0|  2021-01-11|2021-01-11 15:15:00|       0.00478|             1|  gain|\n",
      "|2021-01-11 15:45:00|        8|           1451|           181.375|             254|             31.75|             123|            15.375|               535|            66.875|               8|                     7|           155.875|                         7|                         1|                     0.875|                     0.125|2021-01-11T15:30:...| 845.11|847.715| 851.37| 843.95|1747591|        0|           0|  2021-01-11|2021-01-11 15:30:00|      -0.00307|             0|  loss|\n",
      "|2021-01-11 16:00:00|        7|            161|              23.0|               6|0.8571428571428571|              28|               4.0|                 7|               1.0|               7|                     7|112.85714285714286|                         4|                         2|        0.5714285714285714|        0.2857142857142857|2021-01-11T15:45:...|843.835| 844.96|  847.0|837.075|2042820|        0|           0|  2021-01-11|2021-01-11 15:45:00|      -0.00133|             0|  loss|\n",
      "|2021-01-11 16:15:00|        7|            547| 78.14285714285714|              12|1.7142857142857142|              74|10.571428571428571|                40| 5.714285714285714|               7|                     7|110.85714285714286|                         4|                         3|        0.5714285714285714|       0.42857142857142855|2021-01-11T16:00:...| 835.01| 843.66|844.247|834.821|1524954|        0|           0|  2021-01-11|2021-01-11 16:00:00|      -0.01025|             0|  loss|\n",
      "|2021-01-11 16:30:00|        5|            290|              58.0|               7|               1.4|              26|               5.2|                50|              10.0|               5|                     5|             165.8|                         3|                         2|                       0.6|                       0.4|2021-01-11T16:15:...|839.558| 835.06| 844.33| 833.39|1724704|        0|           0|  2021-01-11|2021-01-11 16:15:00|       0.00539|             1|  gain|\n",
      "|2021-01-11 16:45:00|       12|          27625|2302.0833333333335|              48|               4.0|              80| 6.666666666666667|              1140|              95.0|              11|                     9|139.91666666666666|                         8|                         4|        0.6666666666666666|        0.3333333333333333|2021-01-11T16:30:...|835.523| 839.52|  840.5| 834.32|1091308|        0|           0|  2021-01-11|2021-01-11 16:30:00|      -0.00476|             0|  loss|\n",
      "|2021-01-11 17:00:00|        6|            142|23.666666666666668|               6|               1.0|              17|2.8333333333333335|                21|               3.5|               6|                     6|128.16666666666666|                         3|                         2|                       0.5|        0.3333333333333333|2021-01-11T16:45:...|838.099| 835.81| 839.99| 835.33| 792522|        0|           0|  2021-01-11|2021-01-11 16:45:00|       0.00274|             1|  gain|\n",
      "+-------------------+---------+---------------+------------------+----------------+------------------+----------------+------------------+------------------+------------------+----------------+----------------------+------------------+--------------------------+--------------------------+--------------------------+--------------------------+--------------------+-------+-------+-------+-------+-------+---------+------------+------------+-------------------+--------------+--------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 50.6 ms, sys: 3.67 ms, total: 54.3 ms\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "aggregated_tweets_and_stock_df = {}\n",
    "\n",
    "for company_code in tweets_with_sentiment_and_stock_results_df.keys():\n",
    "    aggregated_tweets_and_stock_df[company_code] = {}\n",
    "    \n",
    "    for ticker_interval in tweets_with_sentiment_and_stock_results_df[company_code].keys():\n",
    "               \n",
    "        if company_code != 'TSLA' or ticker_interval != \"15\":\n",
    "            continue\n",
    "        \n",
    "        aggregated_data = tweets_with_sentiment_and_stock_results_df[company_code][ticker_interval] \\\n",
    "            .groupBy(\"close_timestamp\") \\\n",
    "            .agg( \\\n",
    "                F.count('id'), \\\n",
    "                F.sum('like_count'), \\\n",
    "                F.avg('like_count'), \\\n",
    "                F.sum('quote_count'), \\\n",
    "                F.avg('quote_count'), \\\n",
    "                F.sum('reply_count'), \\\n",
    "                F.avg('reply_count'), \\\n",
    "                F.sum('retweet_count'), \\\n",
    "                F.avg('retweet_count'), \\\n",
    "                F.countDistinct('author_id'), \\\n",
    "                F.countDistinct('conversation_id'), \\\n",
    "                F.avg(length('text')) , \\\n",
    "                F.sum('is_sentiment_positive'), \\\n",
    "                F.sum('is_sentiment_negative'), \\\n",
    "                F.avg('is_sentiment_positive'), \\\n",
    "                F.avg('is_sentiment_negative') \\\n",
    "                ) \\\n",
    "            .orderBy(\"close_timestamp\", ascending=True)\n",
    "        \n",
    "        # F.sum('is_sentiment_positive') / F.sum('is_sentiment_negative'), \\\n",
    "        \n",
    "        aggregated_tweets_and_stock_df[company_code][ticker_interval] = aggregated_data \\\n",
    "            .join(yfinance_data_dfs[company_code][ticker_interval], on=\"close_timestamp\", how=\"outer\") \\\n",
    "            .orderBy(\"close_timestamp\", ascending=True) \\\n",
    "            .dropna() \\\n",
    "            \n",
    "        aggregated_tweets_and_stock_df[company_code][ticker_interval].show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- close_timestamp: timestamp (nullable = true)\n",
      " |-- count(id): long (nullable = true)\n",
      " |-- sum(like_count): long (nullable = true)\n",
      " |-- avg(like_count): double (nullable = true)\n",
      " |-- sum(quote_count): long (nullable = true)\n",
      " |-- avg(quote_count): double (nullable = true)\n",
      " |-- sum(reply_count): long (nullable = true)\n",
      " |-- avg(reply_count): double (nullable = true)\n",
      " |-- sum(retweet_count): long (nullable = true)\n",
      " |-- avg(retweet_count): double (nullable = true)\n",
      " |-- count(author_id): long (nullable = true)\n",
      " |-- count(conversation_id): long (nullable = true)\n",
      " |-- avg(length(text)): double (nullable = true)\n",
      " |-- sum(is_sentiment_positive): long (nullable = true)\n",
      " |-- sum(is_sentiment_negative): long (nullable = true)\n",
      " |-- avg(is_sentiment_positive): double (nullable = true)\n",
      " |-- avg(is_sentiment_negative): double (nullable = true)\n",
      " |-- records_datetime: string (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- dividends: long (nullable = true)\n",
      " |-- stock_splits: long (nullable = true)\n",
      " |-- records_date: date (nullable = true)\n",
      " |-- open_timestamp: timestamp (nullable = true)\n",
      " |-- result_percent: double (nullable = true)\n",
      " |-- result_numeric: integer (nullable = true)\n",
      " |-- result: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregated_tweets_and_stock_df[\"TSLA\"][\"15\"].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 30)\n",
      "CPU times: user 4.42 ms, sys: 0 ns, total: 4.42 ms\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print((aggregated_tweets_and_stock_df[\"TSLA\"][\"15\"].count(), len(aggregated_tweets_and_stock_df[\"TSLA\"][\"15\"].columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_tweets_and_stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+--------------------------+---------+---------------+------------------+----------------+-------------------+----------------+------------------+------------------+------------------+------------------+----------------+----------------------+--------------+--------------+\n",
      "|    close_timestamp|avg(is_sentiment_positive)|avg(is_sentiment_negative)|count(id)|sum(like_count)|   avg(like_count)|sum(quote_count)|   avg(quote_count)|sum(reply_count)|  avg(reply_count)|sum(retweet_count)|avg(retweet_count)| avg(length(text))|count(author_id)|count(conversation_id)|result_percent|result_numeric|\n",
      "+-------------------+--------------------------+--------------------------+---------+---------------+------------------+----------------+-------------------+----------------+------------------+------------------+------------------+------------------+----------------+----------------------+--------------+--------------+\n",
      "|2021-01-11 14:45:00|        0.3333333333333333|        0.6666666666666666|        3|            174|              58.0|               1| 0.3333333333333333|              15|               5.0|                16| 5.333333333333333|             122.0|               3|                     3|      -0.01915|             0|\n",
      "|2021-01-11 15:00:00|                     0.875|                     0.125|       16|            792|              49.5|               9|             0.5625|              85|            5.3125|                41|            2.5625|           156.875|              15|                    15|       0.01222|             1|\n",
      "|2021-01-11 15:15:00|                       0.0|                       1.0|        3|            430|143.33333333333334|               4| 1.3333333333333333|              28| 9.333333333333334|                29| 9.666666666666666|122.66666666666667|               3|                     3|       0.00604|             1|\n",
      "|2021-01-11 15:30:00|                       1.0|                       0.0|        8|            302|             37.75|               1|              0.125|              26|              3.25|                18|              2.25|           136.375|               7|                     8|       0.00478|             1|\n",
      "|2021-01-11 15:45:00|                     0.875|                     0.125|        8|           1451|           181.375|             254|              31.75|             123|            15.375|               535|            66.875|           155.875|               8|                     7|      -0.00307|             0|\n",
      "|2021-01-11 16:00:00|        0.5714285714285714|        0.2857142857142857|        7|            161|              23.0|               6| 0.8571428571428571|              28|               4.0|                 7|               1.0|112.85714285714286|               7|                     7|      -0.00133|             0|\n",
      "|2021-01-11 16:15:00|        0.5714285714285714|       0.42857142857142855|        7|            547| 78.14285714285714|              12| 1.7142857142857142|              74|10.571428571428571|                40| 5.714285714285714|110.85714285714286|               7|                     7|      -0.01025|             0|\n",
      "|2021-01-11 16:30:00|                       0.6|                       0.4|        5|            290|              58.0|               7|                1.4|              26|               5.2|                50|              10.0|             165.8|               5|                     5|       0.00539|             1|\n",
      "|2021-01-11 16:45:00|        0.6666666666666666|        0.3333333333333333|       12|          27625|2302.0833333333335|              48|                4.0|              80| 6.666666666666667|              1140|              95.0|139.91666666666666|              11|                     9|      -0.00476|             0|\n",
      "|2021-01-11 17:00:00|                       0.5|        0.3333333333333333|        6|            142|23.666666666666668|               6|                1.0|              17|2.8333333333333335|                21|               3.5|128.16666666666666|               6|                     6|       0.00274|             1|\n",
      "|2021-01-11 17:15:00|                      0.75|                       0.0|        4|            376|              94.0|               2|                0.5|              13|              3.25|                 8|               2.0|             125.5|               4|                     4|       0.00174|             1|\n",
      "|2021-01-11 17:30:00|        0.5714285714285714|       0.42857142857142855|        7|            164|23.428571428571427|               1|0.14285714285714285|               6|0.8571428571428571|                19|2.7142857142857144|181.14285714285714|               7|                     7|      -0.00422|             0|\n",
      "|2021-01-11 17:45:00|                       1.0|                       0.0|        6|            277|46.166666666666664|               6|                1.0|              21|               3.5|                39|               6.5|147.16666666666666|               6|                     6|        2.8E-4|             1|\n",
      "|2021-01-11 18:00:00|        0.8333333333333334|       0.08333333333333333|       12|           1530|             127.5|               8| 0.6666666666666666|              43|3.5833333333333335|                64| 5.333333333333333|113.66666666666667|              12|                     4|        4.0E-5|             1|\n",
      "|2021-01-11 18:15:00|        0.6666666666666666|        0.3333333333333333|        6|            303|              50.5|               0|                0.0|              13|2.1666666666666665|                11|1.8333333333333333|135.83333333333334|               6|                     3|      -0.00135|             0|\n",
      "|2021-01-11 18:30:00|                       0.5|                       0.0|        2|             42|              21.0|               0|                0.0|               3|               1.5|                 5|               2.5|             111.0|               2|                     2|      -0.00797|             0|\n",
      "|2021-01-11 18:45:00|        0.5714285714285714|       0.42857142857142855|        7|           1181|168.71428571428572|               0|                0.0|               4|0.5714285714285714|                10|1.4285714285714286|116.42857142857143|               7|                     4|      -0.00121|             0|\n",
      "|2021-01-11 19:00:00|                       1.0|                       0.0|        5|            182|              36.4|               5|                1.0|              21|               4.2|                30|               6.0|             154.8|               5|                     5|       0.00262|             1|\n",
      "|2021-01-11 19:15:00|                     0.375|                     0.625|        8|           1204|             150.5|               8|                1.0|              35|             4.375|               127|            15.875|           158.875|               8|                     7|      -0.00497|             0|\n",
      "|2021-01-11 19:30:00|        0.3333333333333333|        0.6666666666666666|        3|             83|27.666666666666668|               0|                0.0|              10|3.3333333333333335|                 4|1.3333333333333333|168.66666666666666|               3|                     2|      -0.00491|             0|\n",
      "|2021-01-11 19:45:00|        0.8823529411764706|       0.11764705882352941|       17|           2380|             140.0|              92|  5.411764705882353|             185|10.882352941176471|               340|              20.0|162.47058823529412|              15|                    13|       0.00659|             1|\n",
      "|2021-01-11 20:00:00|                      0.75|                       0.0|        4|            100|              25.0|               1|               0.25|               8|               2.0|                 6|               1.5|             125.0|               4|                     2|      -0.00514|             0|\n",
      "|2021-01-11 20:30:00|                      0.75|       0.16666666666666666|       12|            265|22.083333333333332|               2|0.16666666666666666|              47|3.9166666666666665|                42|               3.5|146.16666666666666|              12|                    12|      -0.01187|             0|\n",
      "|2021-01-11 20:45:00|                      0.75|                      0.25|        8|            353|            44.125|               7|              0.875|              69|             8.625|                16|               2.0|           166.875|               8|                     8|       0.00367|             1|\n",
      "|2021-01-11 21:00:00|                      0.25|                       0.5|        4|           1153|            288.25|               3|               0.75|              38|               9.5|                29|              7.25|             179.0|               4|                     3|       0.00217|             1|\n",
      "|2021-01-12 14:45:00|        0.7777777777777778|        0.2222222222222222|        9|            718| 79.77777777777777|              17| 1.8888888888888888|              46| 5.111111111111111|               109| 12.11111111111111|145.66666666666666|               9|                     9|       0.01767|             1|\n",
      "|2021-01-12 15:00:00|                      0.75|                       0.0|        4|            417|            104.25|               1|               0.25|              17|              4.25|                42|              10.5|             106.5|               4|                     4|       0.00362|             1|\n",
      "|2021-01-12 15:15:00|        0.8333333333333334|       0.16666666666666666|        6|            903|             150.5|              11| 1.8333333333333333|              76|12.666666666666666|                60|              10.0| 90.83333333333333|               6|                     6|       0.00926|             1|\n",
      "|2021-01-12 15:30:00|        0.6363636363636364|       0.36363636363636365|       11|            831| 75.54545454545455|              11|                1.0|              74|6.7272727272727275|               132|              12.0| 167.8181818181818|              11|                    10|         0.004|             1|\n",
      "|2021-01-12 15:45:00|                       0.6|                       0.2|        5|            208|              41.6|               1|                0.2|               9|               1.8|                 9|               1.8|             132.0|               5|                     5|        0.0025|             1|\n",
      "|2021-01-12 16:00:00|                      0.75|                       0.0|        4|            432|             108.0|              14|                3.5|              12|               3.0|               174|              43.5|            150.25|               4|                     4|      -0.00177|             0|\n",
      "|2021-01-12 16:15:00|        0.6666666666666666|        0.3333333333333333|        3|             74|24.666666666666668|               4| 1.3333333333333333|               6|               2.0|                15|               5.0|             141.0|               3|                     3|      -0.00188|             0|\n",
      "|2021-01-12 16:30:00|                       0.5|                       0.5|        6|            179|29.833333333333332|               5| 0.8333333333333334|               6|               1.0|                20|3.3333333333333335|             154.0|               6|                     6|       0.00343|             1|\n",
      "|2021-01-12 16:45:00|                     0.875|                       0.0|        8|           2510|            313.75|              65|              8.125|              51|             6.375|               414|             51.75|             172.0|               7|                     7|        6.6E-4|             1|\n",
      "|2021-01-12 17:00:00|                      0.75|                      0.25|        8|            575|            71.875|              17|              2.125|              70|              8.75|                62|              7.75|            150.75|               7|                     8|      -0.00316|             0|\n",
      "|2021-01-12 17:15:00|                       1.0|                       0.0|        2|            219|             109.5|               0|                0.0|               2|               1.0|                15|               7.5|             198.5|               2|                     2|      -0.01093|             0|\n",
      "|2021-01-12 17:30:00|                       0.5|                       0.5|        2|             31|              15.5|               0|                0.0|               0|               0.0|                14|               7.0|             254.0|               2|                     2|       0.00874|             1|\n",
      "|2021-01-12 17:45:00|                       1.0|                       0.0|        3|             36|              12.0|               0|                0.0|               2|0.6666666666666666|                 3|               1.0|121.33333333333333|               3|                     3|      -0.00262|             0|\n",
      "|2021-01-12 18:00:00|        0.8571428571428571|       0.14285714285714285|        7|            379|54.142857142857146|               4| 0.5714285714285714|              19|2.7142857142857144|                53| 7.571428571428571|189.85714285714286|               7|                     7|       0.00269|             1|\n",
      "|2021-01-12 18:15:00|                       1.0|                       0.0|        1|             11|              11.0|               0|                0.0|               2|               2.0|                 1|               1.0|             267.0|               1|                     1|       0.00102|             1|\n",
      "|2021-01-12 18:30:00|        0.6666666666666666|        0.3333333333333333|        6|            167|27.833333333333332|               4| 0.6666666666666666|              14|2.3333333333333335|                12|               2.0|             125.5|               6|                     6|       -3.5E-4|             0|\n",
      "|2021-01-12 18:45:00|                       1.0|                       0.0|        6|            655|109.16666666666667|              27|                4.5|              15|               2.5|               175|29.166666666666668|             204.0|               5|                     6|        9.5E-4|             1|\n",
      "|2021-01-12 19:00:00|        0.8571428571428571|                       0.0|        7|            507| 72.42857142857143|              10| 1.4285714285714286|              55| 7.857142857142857|                50| 7.142857142857143|132.14285714285714|               7|                     7|      -0.00442|             0|\n",
      "|2021-01-12 19:15:00|        0.7272727272727273|       0.18181818181818182|       11|            692| 62.90909090909091|               4|0.36363636363636365|              49| 4.454545454545454|                64| 5.818181818181818| 179.0909090909091|              11|                    10|      -0.00104|             0|\n",
      "|2021-01-12 19:30:00|                      0.75|                      0.25|        4|             66|              16.5|               1|               0.25|               3|              0.75|                10|               2.5|            136.25|               4|                     4|      -0.00419|             0|\n",
      "|2021-01-12 19:45:00|                       1.0|                       0.0|        4|            577|            144.25|               5|               1.25|               8|               2.0|                98|              24.5|             97.25|               4|                     4|       0.00378|             1|\n",
      "|2021-01-12 20:00:00|        0.7142857142857143|       0.14285714285714285|        7|            172|24.571428571428573|               2| 0.2857142857142857|               9|1.2857142857142858|                13|1.8571428571428572|173.14285714285714|               7|                     7|       -2.1E-4|             0|\n",
      "|2021-01-12 20:15:00|        0.8571428571428571|       0.14285714285714285|        7|           4236| 605.1428571428571|              42|                6.0|              91|              13.0|               394|56.285714285714285|             201.0|               7|                     7|        6.7E-4|             1|\n",
      "|2021-01-12 20:30:00|        0.8333333333333334|       0.16666666666666666|        6|            137|22.833333333333332|               1|0.16666666666666666|              39|               6.5|                 6|               1.0| 93.16666666666667|               6|                     5|       0.00457|             1|\n",
      "|2021-01-12 20:45:00|                       0.5|                       0.5|        4|            251|             62.75|               1|               0.25|              27|              6.75|                 9|              2.25|             108.5|               4|                     4|      -0.00461|             0|\n",
      "|2021-01-12 21:00:00|        0.3333333333333333|        0.6666666666666666|        3|            187|62.333333333333336|               2| 0.6666666666666666|               3|               1.0|                16| 5.333333333333333|144.66666666666666|               3|                     3|      -0.00563|             0|\n",
      "|2021-01-13 15:00:00|                      0.75|                      0.25|        8|            423|            52.875|               0|                0.0|              22|              2.75|                17|             2.125|             171.0|               8|                     8|        5.0E-4|             1|\n",
      "|2021-01-13 15:15:00|                       1.0|                       0.0|        8|           1318|            164.75|               4|                0.5|              74|              9.25|                63|             7.875|            140.25|               8|                     7|      -0.00621|             0|\n",
      "|2021-01-13 15:30:00|                       0.8|                       0.2|        5|            199|              39.8|               9|                1.8|              26|               5.2|                18|               3.6|             222.0|               5|                     5|      -0.00125|             0|\n",
      "|2021-01-13 15:45:00|                       1.0|                       0.0|        3|            358|119.33333333333333|               3|                1.0|             131|43.666666666666664|                 7|2.3333333333333335| 89.33333333333333|               3|                     3|       0.00473|             1|\n",
      "|2021-01-13 16:00:00|        0.8571428571428571|       0.14285714285714285|        7|            186|26.571428571428573|               2| 0.2857142857142857|              21|               3.0|                16|2.2857142857142856|             173.0|               7|                     7|        2.7E-4|             1|\n",
      "|2021-01-13 16:15:00|        0.6666666666666666|        0.3333333333333333|        3|            222|              74.0|               1| 0.3333333333333333|              26| 8.666666666666666|                12|               4.0|222.66666666666666|               3|                     3|      -0.00388|             0|\n",
      "|2021-01-13 16:30:00|        0.6666666666666666|       0.16666666666666666|        6|           1426|237.66666666666666|              12|                2.0|             135|              22.5|                62|10.333333333333334|211.33333333333334|               6|                     5|        0.0019|             1|\n",
      "|2021-01-13 16:45:00|        0.9090909090909091|       0.09090909090909091|       11|           1134| 103.0909090909091|              15| 1.3636363636363635|              40|3.6363636363636362|               126|11.454545454545455| 149.0909090909091|              10|                    10|       -5.9E-4|             0|\n",
      "|2021-01-13 17:00:00|        0.7777777777777778|        0.2222222222222222|        9|            717| 79.66666666666667|               2| 0.2222222222222222|              58| 6.444444444444445|                80|  8.88888888888889|128.77777777777777|               9|                     8|      -0.00477|             0|\n",
      "|2021-01-13 17:15:00|                       1.0|                       0.0|        5|           1062|             212.4|              12|                2.4|              39|               7.8|               292|              58.4|             153.8|               5|                     5|       -4.6E-4|             0|\n",
      "|2021-01-13 17:30:00|                       1.0|                       0.0|        1|             15|              15.0|               1|                1.0|               1|               1.0|                 0|               0.0|              70.0|               1|                     1|       0.00192|             1|\n",
      "|2021-01-13 17:45:00|                       0.5|                       0.5|        8|           3185|           398.125|              38|               4.75|             202|             25.25|               273|            34.125|           151.125|               8|                     7|      -0.00346|             0|\n",
      "|2021-01-13 18:00:00|                       1.0|                       0.0|        6|            386| 64.33333333333333|               7| 1.1666666666666667|              26| 4.333333333333333|                28| 4.666666666666667|128.83333333333334|               6|                     6|       0.00426|             1|\n",
      "|2021-01-13 18:15:00|                       0.5|                       0.0|        2|            101|              50.5|               0|                0.0|               9|               4.5|                 0|               0.0|             193.0|               2|                     2|      -0.00269|             0|\n",
      "|2021-01-13 18:30:00|                       1.0|                       0.0|        1|             21|              21.0|               0|                0.0|               1|               1.0|                 3|               3.0|             111.0|               1|                     1|        2.5E-4|             1|\n",
      "|2021-01-13 18:45:00|        0.6666666666666666|        0.3333333333333333|        6|            184|30.666666666666668|               0|                0.0|              74|12.333333333333334|                 9|               1.5|137.16666666666666|               6|                     3|       0.00173|             1|\n",
      "|2021-01-13 19:15:00|                      0.75|                      0.25|        4|             70|              17.5|               0|                0.0|               4|               1.0|                 1|              0.25|             63.75|               4|                     1|       0.00963|             1|\n",
      "|2021-01-13 19:30:00|                       0.5|                      0.25|        4|            494|             123.5|               1|               0.25|              66|              16.5|                17|              4.25|            183.75|               4|                     3|       0.00197|             1|\n",
      "|2021-01-13 19:45:00|                       1.0|                       0.0|        1|            687|             687.0|               0|                0.0|               5|               5.0|                 5|               5.0|              87.0|               1|                     1|       -0.0044|             0|\n",
      "|2021-01-13 20:00:00|                       0.5|                       0.5|        2|             95|              47.5|               4|                2.0|               9|               4.5|                14|               7.0|             104.0|               2|                     2|       0.00628|             1|\n",
      "|2021-01-13 20:15:00|                       1.0|                       0.0|        2|             40|              20.0|               1|                0.5|               0|               0.0|                 6|               3.0|             203.0|               2|                     2|       -2.4E-4|             0|\n",
      "|2021-01-13 20:30:00|        0.6666666666666666|        0.3333333333333333|        3|             53|17.666666666666668|               0|                0.0|              11|3.6666666666666665|                 2|0.6666666666666666|184.33333333333334|               3|                     3|      -0.00438|             0|\n",
      "|2021-01-13 20:45:00|                     0.875|                     0.125|        8|            422|             52.75|               8|                1.0|              23|             2.875|                92|              11.5|           164.625|               8|                     8|       0.00266|             1|\n",
      "|2021-01-13 21:00:00|                       0.8|                       0.0|        5|           4150|             830.0|              17|                3.4|             175|              35.0|               144|              28.8|             323.2|               5|                     5|        6.8E-4|             1|\n",
      "|2021-01-14 14:45:00|        0.9090909090909091|       0.09090909090909091|       11|            709| 64.45454545454545|               9| 0.8181818181818182|              36| 3.272727272727273|                42|3.8181818181818183|             145.0|              11|                    11|       0.00396|             1|\n",
      "|2021-01-14 15:00:00|                      0.75|                      0.25|        4|             57|             14.25|               2|                0.5|               8|               2.0|                 6|               1.5|             214.5|               3|                     3|      -0.00267|             0|\n",
      "|2021-01-14 15:15:00|                      0.75|                      0.25|        4|            278|              69.5|               0|                0.0|              10|               2.5|                10|               2.5|            135.25|               4|                     4|       0.01498|             1|\n",
      "|2021-01-14 15:30:00|        0.6666666666666666|        0.3333333333333333|        3|            107|35.666666666666664|               2| 0.6666666666666666|               5|1.6666666666666667|                 7|2.3333333333333335|187.66666666666666|               3|                     3|      -0.00148|             0|\n",
      "|2021-01-14 15:45:00|                      0.75|       0.16666666666666666|       12|            494|41.166666666666664|              17| 1.4166666666666667|              53| 4.416666666666667|                38|3.1666666666666665|             124.0|              12|                    12|        0.0036|             1|\n",
      "|2021-01-14 16:00:00|                       0.5|                       0.5|        6|           1030|171.66666666666666|              15|                2.5|              59| 9.833333333333334|               141|              23.5|162.16666666666666|               6|                     6|      -0.00482|             0|\n",
      "|2021-01-14 16:15:00|                       1.0|                       0.0|        8|           1691|           211.375|              17|              2.125|              31|             3.875|               220|              27.5|            92.375|               8|                     8|        8.5E-4|             1|\n",
      "|2021-01-14 16:30:00|                       1.0|                       0.0|        3|             30|              10.0|               0|                0.0|               1|0.3333333333333333|                 1|0.3333333333333333|190.66666666666666|               3|                     3|      -0.00503|             0|\n",
      "|2021-01-14 16:45:00|        0.6363636363636364|        0.2727272727272727|       11|            593| 53.90909090909091|              18| 1.6363636363636365|              57| 5.181818181818182|                55|               5.0| 130.1818181818182|              11|                    11|       0.00451|             1|\n",
      "|2021-01-14 17:00:00|                       0.4|                       0.6|        5|            444|              88.8|              11|                2.2|              15|               3.0|                45|               9.0|             180.0|               5|                     5|      -0.00455|             0|\n",
      "|2021-01-14 17:15:00|        0.8571428571428571|       0.14285714285714285|        7|           1023|146.14285714285714|               7|                1.0|              21|               3.0|                48| 6.857142857142857|106.85714285714286|               7|                     7|        4.0E-4|             1|\n",
      "|2021-01-14 17:30:00|                       1.0|                       0.0|        3|             46|15.333333333333334|               0|                0.0|               4|1.3333333333333333|                 4|1.3333333333333333|112.66666666666667|               3|                     3|       0.00286|             1|\n",
      "|2021-01-14 17:45:00|                       1.0|                       0.0|        5|            416|              83.2|               2|                0.4|               7|               1.4|                42|               8.4|             186.6|               5|                     5|      -0.00428|             0|\n",
      "|2021-01-14 18:00:00|        0.6666666666666666|        0.3333333333333333|        3|            126|              42.0|               4| 1.3333333333333333|              29| 9.666666666666666|                15|               5.0| 267.6666666666667|               3|                     3|       0.00205|             1|\n",
      "|2021-01-14 18:15:00|        0.6666666666666666|        0.3333333333333333|        6|            577| 96.16666666666667|               9|                1.5|              63|              10.5|               112|18.666666666666668|170.83333333333334|               6|                     6|      -0.00651|             0|\n",
      "|2021-01-14 18:30:00|        0.8333333333333334|       0.16666666666666666|        6|            154|25.666666666666668|               2| 0.3333333333333333|              16|2.6666666666666665|                14|2.3333333333333335|             240.0|               6|                     6|      -0.00429|             0|\n",
      "|2021-01-14 18:45:00|                       0.8|                       0.0|        5|           1159|             231.8|              19|                3.8|              93|              18.6|               158|              31.6|             177.8|               5|                     5|       0.00491|             1|\n",
      "|2021-01-14 19:00:00|                       1.0|                       0.0|        3|            431|143.66666666666666|               4| 1.3333333333333333|              46|15.333333333333334|                28| 9.333333333333334|189.66666666666666|               3|                     3|      -0.00245|             0|\n",
      "|2021-01-14 19:15:00|        0.8333333333333334|       0.16666666666666666|        6|            383|63.833333333333336|               4| 0.6666666666666666|              26| 4.333333333333333|                73|12.166666666666666|213.66666666666666|               6|                     6|       0.00265|             1|\n",
      "|2021-01-14 19:30:00|        0.8888888888888888|        0.1111111111111111|        9|            311| 34.55555555555556|               4| 0.4444444444444444|              17|1.8888888888888888|                76| 8.444444444444445|140.55555555555554|               9|                     9|       0.00334|             1|\n",
      "|2021-01-14 19:45:00|        0.6666666666666666|        0.3333333333333333|        6|            184|30.666666666666668|               8| 1.3333333333333333|              17|2.8333333333333335|                43| 7.166666666666667|178.66666666666666|               6|                     6|      -0.00282|             0|\n",
      "|2021-01-14 20:00:00|                      0.75|                      0.25|        4|            675|            168.75|               1|               0.25|              14|               3.5|                38|               9.5|            182.75|               4|                     4|      -0.00124|             0|\n",
      "|2021-01-14 20:15:00|        0.8571428571428571|       0.14285714285714285|        7|            467| 66.71428571428571|              11| 1.5714285714285714|              78|11.142857142857142|               132|18.857142857142858|             104.0|               6|                     7|      -0.00132|             0|\n",
      "|2021-01-14 20:30:00|                      0.75|                      0.25|       12|            461|38.416666666666664|               6|                0.5|             118| 9.833333333333334|                33|              2.75|            129.75|              12|                    12|      -0.00133|             0|\n",
      "|2021-01-14 21:00:00|        0.7777777777777778|        0.2222222222222222|        9|           1047|116.33333333333333|               6| 0.6666666666666666|              59| 6.555555555555555|                85| 9.444444444444445|125.66666666666667|               9|                     9|      -0.00395|             0|\n",
      "+-------------------+--------------------------+--------------------------+---------+---------------+------------------+----------------+-------------------+----------------+------------------+------------------+------------------+------------------+----------------+----------------------+--------------+--------------+\n",
      "only showing top 100 rows\n",
      "\n",
      "CPU times: user 10.6 ms, sys: 4.48 ms, total: 15.1 ms\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for company_code in tweets_with_sentiment_and_stock_results_df.keys():  \n",
    "    for ticker_interval in tweets_with_sentiment_and_stock_results_df[company_code].keys():\n",
    "        \n",
    "        if company_code != 'TSLA' or ticker_interval != \"15\":\n",
    "            continue\n",
    "        \n",
    "        aggregated_tweets_and_stock_df[company_code][ticker_interval] \\\n",
    "            .select(\n",
    "                    col(\"close_timestamp\"),\\\n",
    "                    col(\"avg(is_sentiment_positive)\"),\\\n",
    "                    col(\"avg(is_sentiment_negative)\"),\\\n",
    "                    col(\"count(id)\"),\\\n",
    "                    col(\"sum(like_count)\"),\\\n",
    "                    col(\"avg(like_count)\"),\\\n",
    "                    col(\"sum(quote_count)\"),\\\n",
    "                    col(\"avg(quote_count)\"),\\\n",
    "                    col(\"sum(reply_count)\"),\\\n",
    "                    col(\"avg(reply_count)\"),\\\n",
    "                    col(\"sum(retweet_count)\"),\\\n",
    "                    col(\"avg(retweet_count)\"),\\\n",
    "                    col(\"avg(length(text))\"),\\\n",
    "                    col(\"count(author_id)\"),\\\n",
    "                    col(\"count(conversation_id)\"),\\\n",
    "                    col(\"result_percent\"),\\\n",
    "                    col(\"result_numeric\"))\\\n",
    "            .show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare corelation matrix ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company code: TSLA, ticker time: 15\n",
      "Pearson Correlation:\n",
      "+--------------------------+--------------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+--------------------+---------------------+\n",
      "|avg(is_sentiment_positive)|avg(is_sentiment_negative)|count(id)            |sum(like_count)      |avg(like_count)      |sum(quote_count)     |avg(quote_count)     |sum(reply_count)     |avg(reply_count)     |sum(retweet_count)   |avg(retweet_count)   |avg(length(text))    |count(author_id)     |count(conversation_id)|result_percent      |result_numeric       |\n",
      "+--------------------------+--------------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+--------------------+---------------------+\n",
      "|1.0                       |-0.876690272429513        |0.0835515258338656   |-0.020159529845955964|0.0015197331934366626|0.07930909197048792  |0.06810239998430194  |0.014412035153661936 |-0.006737521549794411|0.06156444193589159  |0.07629216954556213  |-0.05203625502848243 |0.07713429365044783  |0.10537698991435378   |0.15422839512538303 |0.21465732633332146  |\n",
      "|-0.876690272429513        |1.0                       |-0.014713564894261611|0.0390840749579089   |-0.002314897250923047|-0.05339804070259973 |-0.049293647647686956|-0.008900714378900667|-0.0254634569423049  |-0.030025521845248152|-0.06742446188411033 |0.058059284383460336 |-0.011316528113585161|-0.03325384815444532  |-0.13035511443217315|-0.21435761515335175 |\n",
      "|0.0835515258338656        |-0.014713564894261611     |1.0                  |0.2670298201537756   |0.1458891545657636   |0.29176446830945524  |0.17037184245020928  |0.5143045037591046   |0.029241693449221933 |0.37410447143848174  |0.20604674277187318  |-0.08685749230762428 |0.9943839784704085   |0.9483698310667914    |0.16631513657527988 |0.10826923273565606  |\n",
      "|-0.020159529845955964     |0.0390840749579089        |0.2670298201537756   |1.0                  |0.9353985436590861   |0.2501733781552683   |0.19093493762082783  |0.29704141368136205  |0.15429520625540502  |0.8549698960095589   |0.681259165970392    |0.011914266859777898 |0.24886935954597394  |0.18632155320773117   |-0.05904938076823555|-0.05336940815865607 |\n",
      "|0.0015197331934366626     |-0.002314897250923047     |0.1458891545657636   |0.9353985436590861   |1.0                  |0.24182410750699126  |0.21518841411953543  |0.3520557801066998   |0.31359764380640814  |0.8070243211155901   |0.7150628961827683   |0.04796142362711476  |0.13091254254387819  |0.07912473483358838   |-0.07504319082342636|-0.05676206289966515 |\n",
      "|0.07930909197048792       |-0.05339804070259973      |0.29176446830945524  |0.2501733781552683   |0.24182410750699126  |1.0                  |0.9737591403912502   |0.46720756547476155  |0.23654600735193007  |0.6205085163715683   |0.6187718343425357   |0.031367334085966224 |0.27704628091941025  |0.24856413933754154   |0.01625376349246684 |-0.016190334831219774|\n",
      "|0.06810239998430194       |-0.049293647647686956     |0.17037184245020928  |0.19093493762082783  |0.21518841411953543  |0.9737591403912502   |1.0                  |0.41506557974843344  |0.27567585044992177  |0.5708038746251684   |0.6350370889236058   |0.05334022498835027  |0.16272301154986216  |0.1509190534857153    |-0.00552742865158079|-0.029594714704152255|\n",
      "|0.014412035153661936      |-0.008900714378900667     |0.5143045037591046   |0.29704141368136205  |0.3520557801066998   |0.46720756547476155  |0.41506557974843344  |1.0                  |0.7813154050005267   |0.4504845479236595   |0.4257823482642218   |0.06709320089641575  |0.5070163672614459   |0.4675819716532825    |0.08240720061450843 |0.0684424204813646   |\n",
      "|-0.006737521549794411     |-0.0254634569423049       |0.029241693449221933 |0.15429520625540502  |0.31359764380640814  |0.23654600735193007  |0.27567585044992177  |0.7813154050005267   |1.0                  |0.21276274638015663  |0.30606259591578594  |0.11330692039092113  |0.03041120924329616  |0.019817461583933126  |0.0329692845570748  |0.05507901956588635  |\n",
      "|0.06156444193589159       |-0.030025521845248152     |0.37410447143848174  |0.8549698960095589   |0.8070243211155901   |0.6205085163715683   |0.5708038746251684   |0.4504845479236595   |0.21276274638015663  |1.0                  |0.9221725705755559   |0.02584242384890669  |0.3503287161425774   |0.3066103812178379    |-0.02495698514702407|-0.03608419930004002 |\n",
      "|0.07629216954556213       |-0.06742446188411033      |0.20604674277187318  |0.681259165970392    |0.7150628961827683   |0.6187718343425357   |0.6350370889236058   |0.4257823482642218   |0.30606259591578594  |0.9221725705755559   |1.0                  |0.08426277838312528  |0.18920846878325687  |0.1734619123007617    |-0.03633864770859452|-0.048191888971198193|\n",
      "|-0.05203625502848243      |0.058059284383460336      |-0.08685749230762428 |0.011914266859777898 |0.04796142362711476  |0.031367334085966224 |0.05334022498835027  |0.06709320089641575  |0.11330692039092113  |0.02584242384890669  |0.08426277838312528  |1.0                  |-0.09656172494004912 |-0.045590168156412036 |-0.08888680197738132|-0.0954622609463157  |\n",
      "|0.07713429365044783       |-0.011316528113585161     |0.9943839784704085   |0.24886935954597394  |0.13091254254387819  |0.27704628091941025  |0.16272301154986216  |0.5070163672614459   |0.03041120924329616  |0.3503287161425774   |0.18920846878325687  |-0.09656172494004912 |1.0                  |0.9460236306147606    |0.1637210093036885  |0.11232436504894448  |\n",
      "|0.10537698991435378       |-0.03325384815444532      |0.9483698310667914   |0.18632155320773117  |0.07912473483358838  |0.24856413933754154  |0.1509190534857153   |0.4675819716532825   |0.019817461583933126 |0.3066103812178379   |0.1734619123007617   |-0.045590168156412036|0.9460236306147606   |1.0                   |0.15656005612413915 |0.09598612939949377  |\n",
      "|0.15422839512538303       |-0.13035511443217315      |0.16631513657527988  |-0.05904938076823555 |-0.07504319082342636 |0.01625376349246684  |-0.00552742865158079 |0.08240720061450843  |0.0329692845570748   |-0.02495698514702407 |-0.03633864770859452 |-0.08888680197738132 |0.1637210093036885   |0.15656005612413915   |1.0                 |0.7369376757576904   |\n",
      "|0.21465732633332146       |-0.21435761515335175      |0.10826923273565606  |-0.05336940815865607 |-0.05676206289966515 |-0.016190334831219774|-0.029594714704152255|0.0684424204813646   |0.05507901956588635  |-0.03608419930004002 |-0.048191888971198193|-0.0954622609463157  |0.11232436504894448  |0.09598612939949377   |0.7369376757576904  |1.0                  |\n",
      "+--------------------------+--------------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+--------------------+---------------------+\n",
      "\n",
      "Spearman Correlation:\n",
      "+--------------------------+--------------------------+---------------------+---------------------+---------------------+-------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------+----------------------+---------------------+--------------------+\n",
      "|avg(is_sentiment_positive)|avg(is_sentiment_negative)|count(id)            |sum(like_count)      |avg(like_count)      |sum(quote_count)   |avg(quote_count)    |sum(reply_count)     |avg(reply_count)     |sum(retweet_count)   |avg(retweet_count)   |avg(length(text))    |count(author_id)    |count(conversation_id)|result_percent       |result_numeric      |\n",
      "+--------------------------+--------------------------+---------------------+---------------------+---------------------+-------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------+----------------------+---------------------+--------------------+\n",
      "|1.0                       |-0.8599842963261035       |0.023408824840204942 |0.049020768707729166 |0.00615753114290989  |0.05401845038482858|0.03624688738341233 |-0.049513326120304235|-0.11975675375660337 |0.06042009831375778  |0.04972961358370764  |-0.06839185452137535 |0.014950317312133305|0.05900052013326348   |0.1807163465387741   |0.24840479948085015 |\n",
      "|-0.8599842963261035       |1.0                       |0.08168281001758225  |-0.028586325249999527|-0.03366779415084634 |0.00267647411391497|0.014464811908071196|0.08895633947175637  |0.11055026320883128  |-0.007106780838923737|-0.015341716141274567|0.09812401056731428  |0.08812587119118558 |0.05001090153818598   |-0.14591970041373817 |-0.23980326017010736|\n",
      "|0.023408824840204942      |0.08168281001758225       |1.0                  |0.6460812126773877   |0.2793658571582254   |0.6288230048174007 |0.35160274233312266 |0.6421067086156139   |0.2452840191668337   |0.6604219686257851   |0.30446835885522316  |-0.057490814566064974|0.9960760654427335  |0.9508924993998128    |0.12433837681676511  |0.09226431429765715 |\n",
      "|0.049020768707729166      |-0.028586325249999527     |0.6460812126773877   |1.0                  |0.8944499772385887   |0.7080910389264404 |0.5906893101774788  |0.7584701778486818   |0.5797690520860342   |0.8449713037132393   |0.7259806564293716   |-0.05002234747473535 |0.6435316311483595  |0.6016958031559863    |0.059636171658412195 |0.03842354561441005 |\n",
      "|0.00615753114290989       |-0.03366779415084634      |0.2793658571582254   |0.8944499772385887   |1.0                  |0.5395118430990531 |0.5445138777830326  |0.6054841581004519   |0.6071937651368212   |0.7060002582370036   |0.7559642090733225   |-0.04659715389788161 |0.27883249826484624 |0.2547963515353043    |-0.014554464504796973|-0.01812035787232388|\n",
      "|0.05401845038482858       |0.00267647411391497       |0.6288230048174007   |0.7080910389264404   |0.5395118430990531   |1.0                |0.9297238575514748  |0.6810841973980298   |0.4745207388920754   |0.8224278570118772   |0.6858444165886326   |0.04387223228784153  |0.6162509544829986  |0.6653333159753093    |0.13296850156518253  |0.09378652997824682 |\n",
      "|0.03624688738341233       |0.014464811908071196      |0.35160274233312266  |0.5906893101774788   |0.5445138777830326   |0.9297238575514748 |1.0                 |0.5663156420459287   |0.48159851618496474  |0.7093001585865693   |0.6912202962749388   |0.05330270975776628  |0.3384217650246897  |0.40652235513303797   |0.10257833104167535  |0.05957992571721596 |\n",
      "|-0.049513326120304235     |0.08895633947175637       |0.6421067086156139   |0.7584701778486818   |0.6054841581004519   |0.6810841973980298 |0.5663156420459287  |1.0                  |0.874041332635056    |0.6852496292444494   |0.5216511304618705   |-0.010869451531608168|0.6393010996802657  |0.6188414420520737    |0.08069786770867356  |0.06158301285368713 |\n",
      "|-0.11975675375660337      |0.11055026320883128       |0.2452840191668337   |0.5797690520860342   |0.6071937651368212   |0.4745207388920754 |0.48159851618496474 |0.874041332635056    |1.0                  |0.47324458875108416  |0.475465103095244    |-0.002535207935255285|0.24549121160262313 |0.24546546603505162   |3.690297140170858E-4 |-0.00720581991581956|\n",
      "|0.06042009831375778       |-0.007106780838923737     |0.6604219686257851   |0.8449713037132393   |0.7060002582370036   |0.8224278570118772 |0.7093001585865693  |0.6852496292444494   |0.47324458875108416  |1.0                  |0.8999684945311174   |0.09851758031480494  |0.651506361879835   |0.6748060736468963    |0.06383163967943503  |0.05262432120340963 |\n",
      "|0.04972961358370764       |-0.015341716141274567     |0.30446835885522316  |0.7259806564293716   |0.7559642090733225   |0.6858444165886326 |0.6912202962749388  |0.5216511304618705   |0.475465103095244    |0.8999684945311174   |1.0                  |0.1448631229574951   |0.29592950915743915 |0.3448680264718063    |0.005253123499516988 |0.003275185957006303|\n",
      "|-0.06839185452137535      |0.09812401056731428       |-0.057490814566064974|-0.05002234747473535 |-0.04659715389788161 |0.04387223228784153|0.05330270975776628 |-0.010869451531608168|-0.002535207935255285|0.09851758031480494  |0.1448631229574951   |1.0                  |-0.06604257518581548|-0.010089358377907108 |-0.14331759013609063 |-0.12989778204871577|\n",
      "|0.014950317312133305      |0.08812587119118558       |0.9960760654427335   |0.6435316311483595   |0.27883249826484624  |0.6162509544829986 |0.3384217650246897  |0.6393010996802657   |0.24549121160262313  |0.651506361879835    |0.29592950915743915  |-0.06604257518581548 |1.0                 |0.9474118745233852    |0.12588592138241886  |0.09625475664698546 |\n",
      "|0.05900052013326348       |0.05001090153818598       |0.9508924993998128   |0.6016958031559863   |0.2547963515353043   |0.6653333159753093 |0.40652235513303797 |0.6188414420520737   |0.24546546603505162  |0.6748060736468963   |0.3448680264718063   |-0.010089358377907108|0.9474118745233852  |1.0                   |0.12628293244996225  |0.08112524768362656 |\n",
      "|0.1807163465387741        |-0.14591970041373817      |0.12433837681676511  |0.059636171658412195 |-0.014554464504796973|0.13296850156518253|0.10257833104167535 |0.08069786770867356  |3.690297140170858E-4 |0.06383163967943503  |0.005253123499516988 |-0.14331759013609063 |0.12588592138241886 |0.12628293244996225   |1.0                  |0.865620056042231   |\n",
      "|0.24840479948085015       |-0.23980326017010736      |0.09226431429765715  |0.03842354561441005  |-0.01812035787232388 |0.09378652997824682|0.05957992571721596 |0.06158301285368713  |-0.00720581991581956 |0.05262432120340963  |0.003275185957006303 |-0.12989778204871577 |0.09625475664698546 |0.08112524768362656   |0.865620056042231    |1.0                 |\n",
      "+--------------------------+--------------------------+---------------------+---------------------+---------------------+-------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------+----------------------+---------------------+--------------------+\n",
      "\n",
      "CPU times: user 6.46 ms, sys: 64.2 ms, total: 70.6 ms\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "for company_code in tweets_with_sentiment_and_stock_results_df.keys():  \n",
    "    for ticker_interval in tweets_with_sentiment_and_stock_results_df[company_code].keys():\n",
    "               \n",
    "        if company_code != 'TSLA' or ticker_interval != \"15\":\n",
    "            continue\n",
    "        \n",
    "        #aggregated_tweets_and_stock_df[company_code][ticker_interval].printSchema()\n",
    "        \n",
    "        df = aggregated_tweets_and_stock_df[company_code][ticker_interval]\\\n",
    "            .select(\\\n",
    "                    col(\"avg(is_sentiment_positive)\"),\\\n",
    "                    col(\"avg(is_sentiment_negative)\"),\\\n",
    "                    col(\"count(id)\"),\\\n",
    "                    col(\"sum(like_count)\"),\\\n",
    "                    col(\"avg(like_count)\"),\\\n",
    "                    col(\"sum(quote_count)\"),\\\n",
    "                    col(\"avg(quote_count)\"),\\\n",
    "                    col(\"sum(reply_count)\"),\\\n",
    "                    col(\"avg(reply_count)\"),\\\n",
    "                    col(\"sum(retweet_count)\"),\\\n",
    "                    col(\"avg(retweet_count)\"),\\\n",
    "                    col(\"avg(length(text))\"),\\\n",
    "                    col(\"count(author_id)\"),\\\n",
    "                    col(\"count(conversation_id)\"),\\\n",
    "                    col(\"result_percent\"),\\\n",
    "                    col(\"result_numeric\")\\\n",
    "                    )\n",
    "        \n",
    "#                     col(\"sum(is_sentiment_positive)\"),\\\n",
    "#                     col(\"sum(is_sentiment_negative)\"),\\\n",
    "#                     col(\"(sum(is_sentiment_positive) / sum(is_sentiment_negative))\"),\\\n",
    "#                     col(\"close\"),\\\n",
    "#                     col(\"open\"),\\\n",
    "#                     col(\"high\"),\\\n",
    "#                     col(\"low\"),\\\n",
    "#                     col(\"volume\"),\\\n",
    "        \n",
    "        assembler = VectorAssembler(inputCols = df.columns, outputCol = \"features\")\n",
    "        assembled = assembler.transform(df)\n",
    "        \n",
    "        print(f'company code: {company_code}, ticker time: {ticker_interval}')\n",
    "        \n",
    "        print(\"Pearson Correlation:\")\n",
    "        pearson_corr = Correlation.corr(assembled, \"features\", \"pearson\")\n",
    "        corr_list = pearson_corr.head()[0].toArray().tolist()\n",
    "        pearson_corr_df = (spark.createDataFrame(corr_list)).toDF(*df.columns)\n",
    "        pearson_corr_df.show(truncate=False)\n",
    "        \n",
    "        print(\"Spearman Correlation:\")\n",
    "        spearman_corr = Correlation.corr(assembled, \"features\", \"spearman\")\n",
    "        corr_list = spearman_corr.head()[0].toArray().tolist()\n",
    "        spearman_corr_df = (spark.createDataFrame(corr_list)).toDF(*df.columns)\n",
    "        spearman_corr_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experiments with Clasifiers ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers based on: https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce \n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# warning - slow :(\n",
    "def unionAll(*dfs):\n",
    "    first, *_ = dfs \n",
    "    return first.sql_ctx.createDataFrame(\n",
    "        first.sql_ctx._sc.union([df.rdd for df in dfs]),\n",
    "        first.schema\n",
    "    )\n",
    "\n",
    "# extremely slow\n",
    "# def unionAll(*dfs):\n",
    "#     return reduce(DataFrame.unionAll, dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.7 ms, sys: 0 ns, total: 44.7 ms\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "        \n",
    "# df = aggregated_tweets_and_stock_df[\"TSLA\"][\"15\"]\\\n",
    "#     .select(\\\n",
    "#         col(\"avg(is_sentiment_positive)\"),\\\n",
    "#         col(\"avg(length(text))\"),\\\n",
    "#         col(\"count(id)\"),\\\n",
    "#         col(\"result\")\\\n",
    "#     )\n",
    "\n",
    "df = unionAll(\n",
    "    aggregated_tweets_and_stock_df['AMZN'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['AMD'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['INTC'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['MCD'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['MSFT'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['NFLX'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['PFE'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['QCOM'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['SBUX'][\"15\"],\\\n",
    "    aggregated_tweets_and_stock_df['TSLA'][\"15\"]\\\n",
    "    )\\\n",
    "    .select(\\\n",
    "        col(\"avg(is_sentiment_positive)\"),\\\n",
    "        col(\"avg(length(text))\"),\\\n",
    "        col(\"count(id)\"),\\\n",
    "        col(\"result\")\\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.22 ms, sys: 0 ns, total: 6.22 ms\n",
      "Wall time: 21.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "categoricalColumns = []\n",
    "stages = []\n",
    "cols = df.columns\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = 'result', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['avg(is_sentiment_positive)', 'avg(length(text))', 'count(id)']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 4)\n",
      "CPU times: user 140 ms, sys: 91.2 ms, total: 231 ms\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- avg(is_sentiment_positive): double (nullable = true)\n",
      " |-- avg(length(text)): double (nullable = true)\n",
      " |-- count(id): long (nullable = true)\n",
      " |-- result: string (nullable = true)\n",
      "\n",
      "CPU times: user 184 ms, sys: 54.6 ms, total: 239 ms\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df = df.select(selectedCols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 861\n",
      "Test Dataset Count: 364\n",
      "CPU times: user 316 ms, sys: 98.7 ms, total: 415 ms\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 2021)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.2 s, sys: 1.07 s, total: 3.27 s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "|label|            features|avg(is_sentiment_positive)| avg(length(text))|count(id)|result|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "|  1.0|[0.5,198.66666666...|                       0.5|198.66666666666666|        6|  gain|[0.15484569788143...|[0.53863426021780...|       0.0|\n",
      "|  1.0| [0.375,164.375,8.0]|                     0.375|           164.375|        8|  gain|[0.16795071738127...|[0.54188925986124...|       0.0|\n",
      "|  0.0|   [0.75,153.25,4.0]|                      0.75|            153.25|        4|  loss|[0.13513513673790...|[0.53373246600133...|       0.0|\n",
      "|  0.0|   [0.625,221.0,8.0]|                     0.625|             221.0|        8|  loss|[0.07418347418833...|[0.51853736810847...|       0.0|\n",
      "|  1.0|[1.0,209.33333333...|                       1.0|209.33333333333334|        6|  gain|[0.00556179311319...|[0.50139044469401...|       0.0|\n",
      "|  1.0|[0.71428571428571...|        0.7142857142857143|265.85714285714283|        7|  gain|[0.04951387659096...|[0.51237594082161...|       0.0|\n",
      "|  0.0|     [0.6,193.0,5.0]|                       0.6|             193.0|        5|  loss|[0.14590136505566...|[0.53641077385739...|       0.0|\n",
      "|  0.0|[0.66666666666666...|        0.6666666666666666|180.66666666666666|        6|  loss|[0.11312188649924...|[0.52825035243426...|       0.0|\n",
      "|  0.0|     [0.5,248.5,2.0]|                       0.5|             248.5|        2|  loss|[0.20828032746443...|[0.55188265851880...|       0.0|\n",
      "|  1.0|     [0.5,224.5,2.0]|                       0.5|             224.5|        2|  gain|[0.21722928563330...|[0.55409476732812...|       0.0|\n",
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 42.6 ms, sys: 524 µs, total: 43.1 ms\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_lr = lrModel.transform(test)\n",
    "predictions_lr.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.5149098160065261\n",
      "CPU times: user 134 ms, sys: 111 ms, total: 245 ms\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "bc_evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', bc_evaluator.evaluate(predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated f1: 0.3760809123863192\n",
      "CPU times: user 136 ms, sys: 115 ms, total: 252 ms\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "mc_evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=\"label\", metricName=\"f1\")\n",
    "print(f\"Calculated f1: {mc_evaluator.evaluate(predictions_lr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 947 ms, sys: 636 ms, total: 1.58 s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "|label|            features|avg(is_sentiment_positive)| avg(length(text))|count(id)|result|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "|  1.0|[0.5,198.66666666...|                       0.5|198.66666666666666|        6|  gain|[11.4070666002165...|[0.57035333001082...|       0.0|\n",
      "|  1.0| [0.375,164.375,8.0]|                     0.375|           164.375|        8|  gain|[10.4718343368009...|[0.52359171684004...|       0.0|\n",
      "|  0.0|   [0.75,153.25,4.0]|                      0.75|            153.25|        4|  loss|[10.8962172032807...|[0.54481086016403...|       0.0|\n",
      "|  0.0|   [0.625,221.0,8.0]|                     0.625|             221.0|        8|  loss|[11.0271511108962...|[0.55135755554481...|       0.0|\n",
      "|  1.0|[1.0,209.33333333...|                       1.0|209.33333333333334|        6|  gain|[12.5058542796955...|[0.62529271398477...|       0.0|\n",
      "|  1.0|[0.71428571428571...|        0.7142857142857143|265.85714285714283|        7|  gain|[9.86161230287572...|[0.49308061514378...|       1.0|\n",
      "|  0.0|     [0.6,193.0,5.0]|                       0.6|             193.0|        5|  loss|[10.9039110895545...|[0.54519555447772...|       0.0|\n",
      "|  0.0|[0.66666666666666...|        0.6666666666666666|180.66666666666666|        6|  loss|[11.2188144402212...|[0.56094072201106...|       0.0|\n",
      "|  0.0|     [0.5,248.5,2.0]|                       0.5|             248.5|        2|  loss|[11.7800111109466...|[0.58900055554733...|       0.0|\n",
      "|  1.0|     [0.5,224.5,2.0]|                       0.5|             224.5|        2|  gain|[12.0602076839607...|[0.60301038419803...|       0.0|\n",
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 23.1 ms, sys: 18.3 ms, total: 41.4 ms\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_rf = rfModel.transform(test)\n",
    "predictions_rf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.514728541647784\n",
      "CPU times: user 170 ms, sys: 79.3 ms, total: 250 ms\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bc_evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(bc_evaluator.evaluate(predictions_rf, {bc_evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated f1: 0.48955225376630057\n",
      "CPU times: user 143 ms, sys: 95.5 ms, total: 238 ms\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc_evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=\"label\", metricName=\"f1\")\n",
    "print(f\"Calculated f1: {mc_evaluator.evaluate(predictions_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.86 s, sys: 3.62 s, total: 10.5 s\n",
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(maxIter=10)\n",
    "gbtModel = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "|label|            features|avg(is_sentiment_positive)| avg(length(text))|count(id)|result|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "|  1.0|[0.5,198.66666666...|                       0.5|198.66666666666666|        6|  gain|[0.11080656558659...|[0.55517764198153...|       0.0|\n",
      "|  1.0| [0.375,164.375,8.0]|                     0.375|           164.375|        8|  gain|[0.12772553356781...|[0.56351773639138...|       0.0|\n",
      "|  0.0|   [0.75,153.25,4.0]|                      0.75|            153.25|        4|  loss|[0.08221245914211...|[0.54101386845980...|       0.0|\n",
      "|  0.0|   [0.625,221.0,8.0]|                     0.625|             221.0|        8|  loss|[-0.1830218737459...|[0.40949733643256...|       1.0|\n",
      "|  1.0|[1.0,209.33333333...|                       1.0|209.33333333333334|        6|  gain|[0.39504538755743...|[0.68785082142790...|       0.0|\n",
      "|  1.0|[0.71428571428571...|        0.7142857142857143|265.85714285714283|        7|  gain|[-0.0351073029892...|[0.48245355670981...|       1.0|\n",
      "|  0.0|     [0.6,193.0,5.0]|                       0.6|             193.0|        5|  loss|[0.11080656558659...|[0.55517764198153...|       0.0|\n",
      "|  0.0|[0.66666666666666...|        0.6666666666666666|180.66666666666666|        6|  loss|[0.16203133263902...|[0.58031403447285...|       0.0|\n",
      "|  0.0|     [0.5,248.5,2.0]|                       0.5|             248.5|        2|  loss|[0.26865964822315...|[0.63118859771443...|       0.0|\n",
      "|  1.0|     [0.5,224.5,2.0]|                       0.5|             224.5|        2|  gain|[0.34132272424013...|[0.66432887810736...|       0.0|\n",
      "+-----+--------------------+--------------------------+------------------+---------+------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 37.7 ms, sys: 0 ns, total: 37.7 ms\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_gbt = gbtModel.transform(test)\n",
    "predictions_gbt.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.5283543309465542\n",
      "CPU times: user 127 ms, sys: 107 ms, total: 234 ms\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bc_evaluator = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(bc_evaluator.evaluate(predictions_gbt, {bc_evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated f1: 0.5035172625931702\n",
      "CPU times: user 79.8 ms, sys: 143 ms, total: 223 ms\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mc_evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=\"label\", metricName=\"f1\")\n",
    "print(f\"Calculated f1: {mc_evaluator.evaluate(predictions_gbt)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
